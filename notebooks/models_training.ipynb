{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90cad02-b620-434e-a578-0babb30bbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (44898, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sarah Silverman’s Hysterical Video For Bernie...</td>\n",
       "      <td>On Monday, Sarah Silverman released a hilariou...</td>\n",
       "      <td>News</td>\n",
       "      <td>March 28, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOOM! CLOCK BOY’S DAD LOSES Defamation Case In...</td>\n",
       "      <td>It s hard to be famous for being a  victim  in...</td>\n",
       "      <td>politics</td>\n",
       "      <td>Jan 10, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump Makes ANOTHER Racist Joke About Mexican...</td>\n",
       "      <td>Donald Trump has been making racist comments a...</td>\n",
       "      <td>News</td>\n",
       "      <td>June 30, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHERIFF ARPAIO Bombshell: Obama’s Birth Certif...</td>\n",
       "      <td>Maricopa County Sheriff Joe Arpaio says a new ...</td>\n",
       "      <td>left-news</td>\n",
       "      <td>Dec 16, 2016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senate Democrats ask Trump attorney general pi...</td>\n",
       "      <td>WASHINGTON (Reuters) - Nine Democratic senator...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>January 17, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Sarah Silverman’s Hysterical Video For Bernie...   \n",
       "1  BOOM! CLOCK BOY’S DAD LOSES Defamation Case In...   \n",
       "2   Trump Makes ANOTHER Racist Joke About Mexican...   \n",
       "3  SHERIFF ARPAIO Bombshell: Obama’s Birth Certif...   \n",
       "4  Senate Democrats ask Trump attorney general pi...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  On Monday, Sarah Silverman released a hilariou...          News   \n",
       "1  It s hard to be famous for being a  victim  in...      politics   \n",
       "2  Donald Trump has been making racist comments a...          News   \n",
       "3  Maricopa County Sheriff Joe Arpaio says a new ...     left-news   \n",
       "4  WASHINGTON (Reuters) - Nine Democratic senator...  politicsNews   \n",
       "\n",
       "                date  label  \n",
       "0     March 28, 2016      0  \n",
       "1       Jan 10, 2017      0  \n",
       "2      June 30, 2016      0  \n",
       "3       Dec 16, 2016      0  \n",
       "4  January 17, 2017       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both CSV files\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "real_df = pd.read_csv(\"True.csv\")\n",
    "\n",
    "# Add a label column\n",
    "fake_df['label'] = 0  # 0 = Fake\n",
    "real_df['label'] = 1  # 1 = Real\n",
    "\n",
    "# Combine datasets\n",
    "data = pd.concat([fake_df, real_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Display basic info\n",
    "print(\"Dataset shape:\", data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f453b789-7a06-4bdb-8a76-eab4e57b9f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fathima\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On Monday, Sarah Silverman released a hilariou...</td>\n",
       "      <td>monday sarah silverman released hilarious vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It s hard to be famous for being a  victim  in...</td>\n",
       "      <td>hard famous victim arab gulf state settles dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump has been making racist comments a...</td>\n",
       "      <td>donald trump making racist comments hispanic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maricopa County Sheriff Joe Arpaio says a new ...</td>\n",
       "      <td>maricopa county sheriff joe arpaio says new vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WASHINGTON (Reuters) - Nine Democratic senator...</td>\n",
       "      <td>washington reuters nine democratic senators as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  On Monday, Sarah Silverman released a hilariou...   \n",
       "1  It s hard to be famous for being a  victim  in...   \n",
       "2  Donald Trump has been making racist comments a...   \n",
       "3  Maricopa County Sheriff Joe Arpaio says a new ...   \n",
       "4  WASHINGTON (Reuters) - Nine Democratic senator...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  monday sarah silverman released hilarious vide...  \n",
       "1  hard famous victim arab gulf state settles dis...  \n",
       "2  donald trump making racist comments hispanic p...  \n",
       "3  maricopa county sheriff joe arpaio says new vi...  \n",
       "4  washington reuters nine democratic senators as...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Simple text cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([c for c in text if c not in string.punctuation])\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply to the 'text' column\n",
    "data['cleaned_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Preview\n",
    "data[['text', 'cleaned_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddf98d19-b099-4184-a975-2b45897f2b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875278396436525\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      4694\n",
      "           1       0.99      0.99      0.99      4286\n",
      "\n",
      "    accuracy                           0.99      8980\n",
      "   macro avg       0.99      0.99      0.99      8980\n",
      "weighted avg       0.99      0.99      0.99      8980\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = TfidfVectorizer(max_df=0.7)\n",
    "X = vectorizer.fit_transform(data['cleaned_text'])\n",
    "y = data['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce70a78-0e11-444e-b51a-54eeb482ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(\"../saved_models\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fed7f015-de6a-4232-8340-3caa32c75693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../saved_models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(model, \"../saved_models/fake_news_model.pkl\")\n",
    "joblib.dump(vectorizer, \"../saved_models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc877ff3-7a2b-49d7-93f4-a682275637a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
